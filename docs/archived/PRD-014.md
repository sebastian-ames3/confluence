# PRD-014: Deployment & Infrastructure Fixes

**Version**: 1.0
**Date**: 2025-12-01
**Phase**: 6 - Production Hardening
**Status**: Planning

---

## Objective

Fix critical deployment issues that would cause the application to fail on Railway. This includes missing system dependencies, database initialization on first deploy, and implementing API-triggered scheduling (since Railway Hobby plan lacks cron).

**Priority**: P0 - Critical (Deployment Blockers)

---

## Background

Three independent reviews identified deployment blockers:
1. `railway.json` lacks system packages (FFmpeg, Chromium) required by collectors
2. No database initialization on first deploy to empty volume
3. Scheduler runs as separate process, not auto-started by Railway
4. Railway Hobby plan has no cron feature - need alternative

---

## Success Criteria

- [ ] Railway deployment includes FFmpeg and Chromium via nixPackages
- [ ] Database auto-initializes on first deploy (runs migrations)
- [ ] API endpoints exist to trigger collection and analysis
- [ ] GitHub Actions workflow triggers collection at 6am/6pm EST
- [ ] Health check verifies database connectivity
- [ ] Deployment tested end-to-end on Railway

---

## Technical Specifications

### Part A: Railway Configuration Updates

**File**: `railway.json`

**Current State**:
```json
{
  "build": {
    "builder": "NIXPACKS",
    "buildCommand": "pip install -r requirements.txt"
  },
  "deploy": {
    "startCommand": "uvicorn backend.app:app --host 0.0.0.0 --port $PORT"
  }
}
```

**Target State**:
```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "NIXPACKS",
    "buildCommand": "pip install -r requirements.txt",
    "nixPackages": ["ffmpeg", "chromium", "chromedriver"]
  },
  "deploy": {
    "startCommand": "python scripts/run_migrations.py && uvicorn backend.app:app --host 0.0.0.0 --port $PORT",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10,
    "healthcheckPath": "/health",
    "healthcheckTimeout": 100
  }
}
```

### Part B: Database Auto-Initialization

**Modification**: `scripts/run_migrations.py`

Add idempotent check - if database doesn't exist or tables missing, initialize schema before running migrations.

```python
def ensure_database_exists():
    """Create database and schema if not exists."""
    db_path = Path("database/confluence.db")
    db_path.parent.mkdir(parents=True, exist_ok=True)

    if not db_path.exists():
        print("First deploy detected - initializing database...")
        # Run schema creation
        init_database()

    # Then run any pending migrations
    run_migrations()
```

### Part C: API Trigger Endpoints

**New File**: `backend/routes/trigger.py`

Create protected endpoints that can be called by GitHub Actions to trigger collection and analysis.

```python
@router.post("/collect")
async def trigger_collection(
    background_tasks: BackgroundTasks,
    sources: Optional[List[str]] = None
):
    """
    Trigger data collection from specified sources.

    Protected endpoint - requires API key.
    Called by GitHub Actions scheduler.
    """
    # Validate API key from header
    # Queue collection task
    # Return job ID for status tracking

@router.post("/analyze")
async def trigger_analysis(
    background_tasks: BackgroundTasks,
    time_window: str = "24h"
):
    """
    Trigger analysis and synthesis generation.

    Protected endpoint - requires API key.
    """
    # Queue analysis task
    # Return job ID

@router.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """Check status of triggered job."""
```

### Part D: GitHub Actions Scheduler

**New File**: `.github/workflows/scheduled-collection.yml`

```yaml
name: Scheduled Collection

on:
  schedule:
    # 6am EST = 11:00 UTC (or 10:00 during DST)
    - cron: '0 11 * * *'
    # 6pm EST = 23:00 UTC (or 22:00 during DST)
    - cron: '0 23 * * *'
  workflow_dispatch:  # Allow manual trigger from GitHub UI

jobs:
  trigger-collection:
    runs-on: ubuntu-latest
    steps:
      - name: Trigger Collection
        run: |
          response=$(curl -s -w "\n%{http_code}" -X POST \
            "${{ secrets.RAILWAY_API_URL }}/api/trigger/collect" \
            -H "X-API-Key: ${{ secrets.TRIGGER_API_KEY }}" \
            -H "Content-Type: application/json")

          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | head -n-1)

          echo "Response: $body"
          echo "HTTP Code: $http_code"

          if [ "$http_code" -ne 200 ] && [ "$http_code" -ne 202 ]; then
            echo "Collection trigger failed!"
            exit 1
          fi

      - name: Wait for Collection
        run: sleep 120  # Wait 2 minutes for collection

      - name: Trigger Synthesis
        run: |
          curl -X POST \
            "${{ secrets.RAILWAY_API_URL }}/api/trigger/analyze" \
            -H "X-API-Key: ${{ secrets.TRIGGER_API_KEY }}" \
            -H "Content-Type: application/json" \
            -d '{"time_window": "24h"}'
```

### Part E: Environment Variables

**New Required Variables** (add to Railway and `.env.example`):

```bash
# Trigger API Key (for GitHub Actions authentication)
TRIGGER_API_KEY=your-secure-random-key-here
```

---

## Implementation Tasks

### Task 14.1: Update railway.json
**Estimate**: 15 minutes

**Actions**:
1. Add `nixPackages` array with ffmpeg, chromium, chromedriver
2. Update `startCommand` to run migrations first
3. Test build locally if possible

### Task 14.2: Make Database Initialization Idempotent
**Estimate**: 1 hour

**Actions**:
1. Modify `scripts/run_migrations.py` to check if DB exists
2. Add schema initialization if first run
3. Ensure migrations are idempotent (can run multiple times safely)
4. Test with empty database directory

### Task 14.3: Create Trigger Endpoints
**Estimate**: 2 hours

**Actions**:
1. Create `backend/routes/trigger.py`
2. Implement `/api/trigger/collect` endpoint
3. Implement `/api/trigger/analyze` endpoint
4. Implement `/api/trigger/status/{job_id}` endpoint
5. Add API key validation middleware
6. Register routes in `app.py`
7. Write tests

### Task 14.4: Create GitHub Actions Workflow
**Estimate**: 1 hour

**Actions**:
1. Create `.github/workflows/scheduled-collection.yml`
2. Configure cron schedule for 6am/6pm EST
3. Add manual trigger capability
4. Configure secrets in GitHub repository settings
5. Test with manual trigger

### Task 14.5: Update Environment Configuration
**Estimate**: 30 minutes

**Actions**:
1. Add `TRIGGER_API_KEY` to `.env.example`
2. Document new variables in README
3. Generate secure key for production
4. Add to Railway environment variables

### Task 14.6: End-to-End Deployment Test
**Estimate**: 1-2 hours

**Actions**:
1. Deploy to Railway
2. Verify nixPackages installed (check FFmpeg, Chrome available)
3. Verify database initialized on first deploy
4. Test trigger endpoints manually
5. Run GitHub Action manually
6. Verify collection and synthesis complete

---

## Testing Plan

### Unit Tests
- Trigger endpoint authentication
- Job status tracking
- Migration idempotency

### Integration Tests
- Full trigger → collection → synthesis flow
- Database initialization from scratch
- GitHub Actions workflow (manual trigger)

### Deployment Tests
- Fresh Railway deploy with empty volume
- Verify FFmpeg available: `which ffmpeg`
- Verify Chrome available: `which chromium`
- Health check passes after deploy

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| nixPackages not available | High | Test build before merge; have fallback Dockerfile |
| GitHub Actions rate limits | Low | 2 runs/day is well under limits |
| Migration fails on deploy | High | Add rollback capability; test locally first |
| API key leaked | Medium | Use GitHub secrets; rotate keys regularly |

---

## Dependencies

- Railway account with deployment configured
- GitHub repository with Actions enabled
- Existing collector and analysis code

---

## Files Modified/Created

**New Files**:
- `backend/routes/trigger.py`
- `.github/workflows/scheduled-collection.yml`

**Modified Files**:
- `railway.json` (add nixPackages, update startCommand)
- `scripts/run_migrations.py` (add initialization check)
- `backend/app.py` (register trigger routes)
- `.env.example` (add TRIGGER_API_KEY)
- `README.md` (document new deployment process)

---

## GitHub Secrets Required

| Secret Name | Description |
|-------------|-------------|
| `RAILWAY_API_URL` | Full URL to Railway deployment (e.g., `https://confluence-production.up.railway.app`) |
| `TRIGGER_API_KEY` | API key for authenticating trigger requests |

---

## Sign-off

**Developer**: ___________  Date: ___________
**Sebastian**: ___________  Date: ___________

---

**Status**: Planning
