# PRD-011: Railway Deployment & Scheduler

**Version**: 1.0  
**Date**: 2025-11-18  
**Phase**: 4 - Dashboard & Deployment  
**Duration**: 3 days  
**Status**: Not Started  
**Dependencies**: PRD-010

---

## Objective

Deploy complete system to Railway with automated scheduling (6am, 6pm), configure Discord local script on Sebastian's laptop.

---

## Success Criteria

- [ ] Accessible at Railway URL
- [ ] 6am collection runs automatically (3 consecutive days)
- [ ] 6pm collection runs automatically (3 consecutive days)
- [ ] Discord script runs on Sebastian's laptop
- [ ] Manual on-demand collection works
- [ ] All credentials secure
- [ ] Monitoring/logging functional

---

## Railway Configuration

### Services
1. **Web Service**: FastAPI backend + frontend
2. **Cron Job**: Scheduled collections (6am, 6pm)
3. **Database**: SQLite persistent volume

### Environment Variables
```
CLAUDE_API_KEY=...
WHISPER_API_KEY=...
YOUTUBE_API_KEY=...
DATABASE_URL=sqlite:///data/confluence.db
SECRET_KEY=...
MACRO42_EMAIL=...
MACRO42_PASSWORD=...
TWITTER_SESSION_TOKEN=...
RAILWAY_ENV=production
```

### railway.json
```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "NIXPACKS"
  },
  "deploy": {
    "startCommand": "uvicorn backend.app:app --host 0.0.0.0 --port $PORT",
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 10
  }
}
```

---

## Scheduling

### Railway Cron Jobs
```python
# backend/scheduler.py

import schedule
import time

def run_6am_collection():
    """Collect from all sources except Discord."""
    # Run macro42, twitter, youtube, substack collectors
    pass

def run_6pm_collection():
    """Collect from all sources except Discord."""
    pass

schedule.every().day.at("06:00").do(run_6am_collection)
schedule.every().day.at("18:00").do(run_6pm_collection)

while True:
    schedule.run_pending()
    time.sleep(60)
```

### Discord Local Script (Sebastian's Laptop)

**Windows Task Scheduler** configuration:
- **Trigger 1**: Daily at 6:00 AM
- **Trigger 2**: Daily at 6:00 PM
- **Action**: Run `python scripts/discord_local.py`
- **Conditions**: Run only if laptop is on
- **Settings**: If missed, run at next startup

**Script Logic**:
```python
# scripts/discord_local.py

import discord_self
import requests
import json

def collect_discord_data():
    # Login with Sebastian's token
    # Collect from channels
    # Download attachments
    # Extract video links
    # Package as JSON
    pass

def upload_to_railway(data):
    railway_url = "https://confluence-production.up.railway.app/api/ingest/discord"
    response = requests.post(railway_url, json=data)
    return response.status_code == 200

if __name__ == "__main__":
    data = collect_discord_data()
    success = upload_to_railway(data)
    if success:
        print("Discord data uploaded successfully")
    else:
        print("Upload failed, will retry next run")
```

---

## Deployment Steps

### Step 1: Prepare Railway Project
1. Create new Railway project
2. Connect GitHub repository
3. Add environment variables
4. Configure persistent volume for database

### Step 2: Deploy Backend
1. Push code to main branch
2. Railway auto-deploys
3. Verify backend accessible
4. Test API endpoints

### Step 3: Setup Cron Service
1. Add cron service in Railway
2. Configure schedule
3. Test manual trigger first
4. Monitor logs for 3 days

### Step 4: Configure Discord Script
1. Install Python on Sebastian's laptop
2. Install dependencies: `pip install discord.py-self requests`
3. Create Windows Task Scheduler tasks
4. Test script manually
5. Verify scheduled runs work

### Step 5: End-to-End Test
1. Let system run for 3 days
2. Verify data collection at 6am, 6pm
3. Check Discord data arrives from laptop
4. Confirm analysis runs automatically
5. Dashboard shows latest data

---

## Tasks

### Task 11.1: Railway Project Setup (2 hours)
Create project, configure env vars, persistent volume.

### Task 11.2: Deploy Backend (2 hours)
Push to GitHub, auto-deploy, verify.

### Task 11.3: Configure Cron Jobs (3 hours)
Setup scheduled collections.

### Task 11.4: Discord Script Setup (3 hours)
Install on Sebastian's laptop, configure Task Scheduler.

### Task 11.5: Monitoring & Logging (3 hours)
Setup logging, error notifications.

### Task 11.6: 3-Day Validation (3 days)
Monitor system for reliability.

### Task 11.7: Documentation (2 hours)
Deployment guide, troubleshooting.

---

## Monitoring

### Logs to Track
- Collection success/failure
- Analysis errors
- API response times
- Database query performance
- Disk space usage

### Alerts (Future)
- Email/SMS if collection fails
- Alert if database grows >1GB
- Alert if API costs exceed $100/month

---

## Security

### Credentials
- Never commit credentials to git
- Use Railway env vars for secrets
- Rotate API keys quarterly

### Access Control
- Railway dashboard: Sebastian only
- Dashboard: No authentication (private URL for now)
- Future: Add login

---

## Backup Strategy

### Database Backup
- Daily automated backup to Railway volume
- Weekly manual export to local machine
- Keep 30 days of backups

### Code Backup
- GitHub repository (private)
- Local clones on Sebastian's machines

---

## Rollback Plan

If deployment fails:
1. Revert GitHub commit
2. Railway auto-deploys previous version
3. Restore database from latest backup

---

## Deliverables

1. Railway project configured
2. Backend deployed and accessible
3. Cron jobs running on schedule
4. Discord script on Sebastian's laptop
5. Monitoring and logging active
6. 3 days of successful operations
7. Deployment documentation

---

## Cost Monitoring

### Railway Plan
- Sebastian has subscription
- Monitor usage to stay within plan

### API Costs (Monthly)
- Claude API: ~$40
- Whisper API: ~$20
- YouTube API: Free (within limits)
- **Total: ~$60/month** (within budget)

---

**Status**: Ready after PRD-010
**Final Deliverable**: Fully operational system
